{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "from newspaper import news_pool\n",
    "\n",
    "urls = newspaper.popular_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot = newspaper.hot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build news sources \n",
    "papers = [newspaper.build(x) for x in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.huffingtonpost.gr',\n",
       " 'https://www.huffingtonpost.kr',\n",
       " 'http://www.huffingtonpost.com',\n",
       " 'https://img.huffingtonpost.com',\n",
       " 'http://www.huffingtonpost.com/entertainment',\n",
       " 'https://www.huffingtonpost.jp',\n",
       " 'http://www.huffingtonpost.com/life',\n",
       " 'https://www.huffingtonpost.es',\n",
       " 'https://www.huffingtonpost.fr',\n",
       " 'https://www.huffingtonpost.co.uk',\n",
       " 'http://www.huffingtonpost.com/voices',\n",
       " 'https://www.huffingtonpost.it']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in papers[0].category_urls()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gr\n",
      "kr\n",
      "base\n",
      "base\n",
      "com/entertainment\n",
      "jp\n",
      "com/life\n",
      "es\n",
      "fr\n",
      "co.uk\n",
      "com/voices\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "def filter_url(u:str)->str:\n",
    "    if u.startswith(\"https://\"):\n",
    "        u = u[8:]\n",
    "    elif u.startswith(\"http://\"):\n",
    "        u= u[7:]\n",
    "    if u.startswith(\"www.\"):\n",
    "        u = u[4:]\n",
    "    if u.endswith(\".com\"):\n",
    "        u = u[:-4]\n",
    "    return u\n",
    "\n",
    "def diff_to_base(durl: str, burl: str):\n",
    "    filtered_durl = filter_url(durl)\n",
    "    filtered_burl = filter_url(burl)\n",
    "    \n",
    "    if filtered_durl.startswith(filtered_burl):\n",
    "        diff = filtered_durl[len(filtered_burl):]\n",
    "        if diff.startswith('.'):\n",
    "            diff = diff[1:]\n",
    "        elif diff.startswith('/'):\n",
    "            diff = diff[1:]\n",
    "        if diff == \"\":\n",
    "            return \"base\"\n",
    "        return diff\n",
    "    return \"base\"\n",
    "    \n",
    "\n",
    "def format_url(u:str)-> str:\n",
    "    u = u.replace(\".\", \"-\")\n",
    "    u = u.replace(\"/\", \":\")\n",
    "\n",
    "for paper in papers[0].category_urls():\n",
    "    print(diff_to_base(paper, papers[0].url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4396\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "news_pool.set(papers, threads_per_source=2)\n",
    "news_pool.join()\n",
    "t2 = time.time()\n",
    "print(int(t2-t1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n",
      "386\n",
      "16\n",
      "0\n",
      "0\n",
      "129\n",
      "423\n",
      "0\n",
      "182\n",
      "14\n",
      "153\n",
      "0\n",
      "22\n",
      "0\n",
      "0\n",
      "144\n",
      "31\n",
      "0\n",
      "119\n",
      "3\n",
      "70\n",
      "0\n",
      "49\n",
      "41\n",
      "0\n",
      "9\n",
      "37\n",
      "2\n",
      "25\n",
      "10\n",
      "56\n",
      "2\n",
      "42\n",
      "42\n",
      "0\n",
      "47\n",
      "0\n",
      "0\n",
      "0\n",
      "40\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "82\n",
      "6\n",
      "0\n",
      "4\n",
      "12\n",
      "10\n",
      "0\n",
      "72\n",
      "30\n",
      "62\n",
      "1\n",
      "18\n",
      "576\n",
      "79\n",
      "8\n",
      "0\n",
      "1\n",
      "5\n",
      "324\n",
      "15\n",
      "78\n",
      "144\n",
      "954\n",
      "0\n",
      "35\n",
      "79\n",
      "20\n",
      "134\n",
      "9\n",
      "7\n",
      "0\n",
      "35\n",
      "22\n",
      "4\n",
      "0\n",
      "0\n",
      "65\n",
      "0\n",
      "12\n",
      "23\n",
      "22\n",
      "272\n",
      "34\n",
      "0\n",
      "43\n",
      "2\n",
      "46\n",
      "0\n",
      "83\n",
      "0\n",
      "15\n",
      "0\n",
      "56\n",
      "62\n",
      "13\n",
      "346\n",
      "0\n",
      "0\n",
      "22\n",
      "48\n",
      "29\n",
      "0\n",
      "165\n",
      "59\n",
      "36\n",
      "0\n",
      "0\n",
      "79\n",
      "48\n",
      "21\n",
      "19\n",
      "83\n",
      "26\n",
      "7\n",
      "57\n",
      "119\n",
      "0\n",
      "173\n",
      "16\n",
      "138\n",
      "0\n",
      "19\n",
      "0\n",
      "0\n",
      "27\n",
      "0\n",
      "6\n",
      "0\n",
      "11\n",
      "131\n",
      "31\n",
      "175\n",
      "2\n",
      "45\n",
      "2\n",
      "63\n",
      "0\n",
      "0\n",
      "0\n",
      "6\n",
      "92\n",
      "13\n",
      "224\n",
      "0\n",
      "0\n",
      "7\n",
      "31\n",
      "32\n",
      "188\n",
      "6\n",
      "298\n",
      "14\n",
      "0\n",
      "60\n",
      "49\n",
      "5\n",
      "0\n",
      "106\n",
      "0\n",
      "113\n",
      "0\n",
      "12\n",
      "0\n",
      "35\n",
      "139\n",
      "22\n",
      "33\n",
      "6\n",
      "0\n",
      "77\n",
      "84\n",
      "1\n",
      "83\n",
      "1\n",
      "1443\n",
      "0\n",
      "0\n",
      "174\n",
      "0\n",
      "0\n",
      "12\n",
      "147\n",
      "4\n",
      "45\n",
      "0\n",
      "40\n",
      "68\n",
      "0\n",
      "13\n",
      "20\n",
      "94\n",
      "0\n",
      "69\n",
      "56\n",
      "94\n",
      "427\n",
      "47\n",
      "6\n",
      "0\n",
      "85\n",
      "10\n",
      "9\n",
      "0\n",
      "0\n",
      "5\n",
      "67\n",
      "6\n",
      "0\n",
      "0\n",
      "44\n",
      "49\n",
      "42\n",
      "14\n",
      "6\n",
      "23\n",
      "6\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "27\n",
      "0\n",
      "141\n",
      "57\n",
      "5\n",
      "36\n",
      "27\n",
      "0\n",
      "0\n",
      "171\n",
      "13\n",
      "0\n",
      "0\n",
      "0\n",
      "36\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for paper in papers:\n",
    "    print(paper.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<newspaper.article.Article object at 0x34d9f2ba0>\n",
      "13343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/a2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(n)\n\u001b[0;32m---> 21\u001b[0m t3 \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mint\u001b[39m(t3\u001b[38;5;241m-\u001b[39mt2))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "articles = [paper.articles for paper in papers]\n",
    "n = 0\n",
    "an = 0\n",
    "for aa in articles:\n",
    "    for a in aa:\n",
    "        try:\n",
    "            a.parse()\n",
    "            a.nlp()\n",
    "            an += 1\n",
    "        except LookupError as E:\n",
    "            n += 1\n",
    "        except newspaper.ArticleException as E:\n",
    "            n+= 1\n",
    "        \n",
    "        #now we have a.keywords, a.summary\n",
    "print(a)\n",
    "print(n)\n",
    "t3 = time.time()\n",
    "print(int(t3-t2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_root_path = \"/Users/a2/code/fin/trade/data/news\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m folder_name \u001b[38;5;241m=\u001b[39m format_url(filter_url(paper\u001b[38;5;241m.\u001b[39murl))\n\u001b[1;32m     32\u001b[0m base_url_to_folder_name[paper\u001b[38;5;241m.\u001b[39murl] \u001b[38;5;241m=\u001b[39m folder_name\n\u001b[0;32m---> 33\u001b[0m paper_folder \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoday_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(paper_folder)\n\u001b[1;32m     35\u001b[0m cat_urls_to_folder_names\u001b[38;5;241m.\u001b[39mappend({})\n",
      "File \u001b[0;32m<frozen posixpath>:90\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n",
      "File \u001b[0;32m<frozen genericpath>:164\u001b[0m, in \u001b[0;36m_check_arg_types\u001b[0;34m(funcname, *args)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() argument must be str, bytes, or os.PathLike object, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "from news import Article\n",
    "from datetime import datetime\n",
    "news_root_path = \"/Users/a2/code/fin/trade/data/news\"\n",
    "\n",
    "def date_to_ddmmjj():\n",
    "    # Datum einlesen\n",
    "    date_obj = datetime.today()\n",
    "    # In gewünschtes Format umwandeln\n",
    "    formatted_date = date_obj.strftime('%d%m%y')\n",
    "    return formatted_date\n",
    "def sort_strings_by_length(strings):\n",
    "    \"\"\"\n",
    "    Sort a list of strings by length, longest string first.\n",
    "\n",
    "    :param strings: List of strings to be sorted\n",
    "    :return: List of strings sorted by length\n",
    "    \"\"\"\n",
    "    return sorted(strings, key=len, reverse=True)\n",
    "\n",
    "today_path = os.path.join(news_root_path, date_to_ddmmjj())\n",
    "\n",
    "\n",
    "### initialize folders for news dump\n",
    "if not os.path.isdir(today_path):\n",
    "    os.mkdir(today_path)\n",
    "# papers[n][articles[m]]\n",
    "    base_url_to_folder_name = {}\n",
    "    cat_urls_to_folder_names = []\n",
    "    for paper in papers:\n",
    "        folder_name = format_url(filter_url(paper.url))\n",
    "        base_url_to_folder_name[paper.url] = folder_name\n",
    "        paper_folder = os.path.join(today_path, folder_name)\n",
    "        os.mkdir(paper_folder)\n",
    "        cat_urls_to_folder_names.append({})\n",
    "        for  u in paper.category_urls():\n",
    "            d = format_url(diff_to_base(u, paper.url))\n",
    "            cat_urls_to_folder_names[-1][u] = d\n",
    "            os.mkdir(os.path.join(paper_folder, d))\n",
    "        \n",
    "\n",
    "#### newsdump\n",
    "for p, ip in enumerate(articles):\n",
    "    paper_url = papers[ip].url\n",
    "    pat = os.path.join(today_path, base_url_to_folder_name[paper_url])\n",
    "    category_urls = sort_strings_by_length(p.category_urls())\n",
    "    for a, ia in enumerate(p):\n",
    "        article_url = a.url\n",
    "        for cat_url in category_urls:\n",
    "            if article_url.startswith(cat_url):\n",
    "                pat = os.path.join(pat, cat_urls_to_folder_names[ip][cat_url])\n",
    "                article_obj = Article(base_url_to_folder_name[paper_url], article_url, str(int(a.publish_date.timestamp())), a.authors, a.title, a.text, a.keywords, a.summary)\n",
    "                with open(pat+\"/A_\"+ hash(a.summary), \"w\") as f:\n",
    "                    f.write(article_obj.get_article())\n",
    "                with open(pat+\"/N_\"+ hash(a.summary), \"w\") as f:\n",
    "                    f.write(article_obj.get_nlp())\n",
    "                break\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
